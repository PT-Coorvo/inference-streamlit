# -*- coding: utf-8 -*-
"""model_2.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iAZx5Y80N5gKKDM-reabGfM93GGKUY-N

# **1. Import Libraries**
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import StandardScaler
import pickle
import joblib
import re
import os
from datetime import datetime, date
from typing import List, Dict, Optional
import warnings

# Suppress warnings untuk output yang bersih
warnings.filterwarnings('ignore')

print("✅ Libraries imported successfully")
print(f"📅 Execution date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

"""# **2. System Class Definition**"""

class CompleteCVRecommendationSystem:
    """
    Complete CV Recommendation System

    Features:
    - Content-based filtering menggunakan TF-IDF
    - Collaborative filtering menggunakan matrix factorization
    - Skills matching dengan fuzzy logic
    - Feature-based scoring
    - Model persistence
    """

    def __init__(self):
        # Data
        self.candidates_data = None

        # Content-Based Models
        self.skills_tfidf_vectorizer = None
        self.skills_tfidf_matrix = None
        self.content_tfidf_vectorizer = None
        self.content_tfidf_matrix = None

        # Collaborative Filtering Models
        self.user_item_matrix = None
        self.svd_model = None
        self.user_factors = None
        self.item_factors = None
        self.predicted_interactions = None

        # Job Profiles
        self.job_profiles = {}

        # Scalers
        self.feature_scaler = StandardScaler()

        # Model metadata
        self.model_version = "1.0"
        self.training_date = None

    def extract_skills_list(self, skills_text):
        """Extract individual skills dari text dengan handling berbagai format"""
        if pd.isna(skills_text):
            return []

        skills_text = str(skills_text).strip()

        # Handle format list dengan tanda kurung siku
        if skills_text.startswith('[') and skills_text.endswith(']'):
            skills_text = skills_text[1:-1]

        # Remove quotes dan clean
        skills_text = skills_text.replace('"', '').replace("'", '')

        # Split berdasarkan delimiter
        skills_list = []
        for delimiter in [',', ';', '|', '\n', '\t']:
            if delimiter in skills_text:
                skills_list = skills_text.split(delimiter)
                break
        else:
            skills_list = [skills_text]

        # Clean each skill
        cleaned_skills = []
        for skill in skills_list:
            skill = skill.strip()
            skill = skill.replace('[', '').replace(']', '')
            if skill and len(skill) > 1:
                cleaned_skills.append(skill)

        return cleaned_skills

    def preprocess_text(self, text):
        """Preprocess text untuk TF-IDF"""
        if pd.isna(text):
            return ""

        text = str(text).lower()
        # Normalisasi
        text = text.replace('&', ' and ')
        text = text.replace('+', ' plus ')
        text = text.replace('#', 'sharp ')
        text = text.replace('.', ' ')
        text = text.replace('-', ' ')
        text = text.replace('/', ' ')

        # Remove special characters
        text = re.sub(r'[^\w\s]', ' ', text)
        text = ' '.join(text.split())

        return text

    def calculate_skills_match(self, candidate_skills, required_skills, debug=False):
        """Calculate skills matching dengan fuzzy logic"""
        if not candidate_skills or not required_skills:
            return 0.0, []

        candidate_lower = [skill.lower().strip() for skill in candidate_skills]
        required_lower = [skill.lower().strip() for skill in required_skills]

        matched = []
        exact_matches = 0
        partial_matches = 0

        for i, req_skill in enumerate(required_lower):
            original_req = required_skills[i] if i < len(required_skills) else req_skill
            found_match = False

            # 1. Exact match
            for j, cand_skill in enumerate(candidate_lower):
                original_cand = candidate_skills[j] if j < len(candidate_skills) else cand_skill

                if req_skill == cand_skill:
                    matched.append(original_req)
                    exact_matches += 1
                    found_match = True
                    if debug:
                        print(f"    ✅ EXACT: '{original_req}' == '{original_cand}'")
                    break

            if found_match:
                continue

            # 2. Partial match - substring
            for j, cand_skill in enumerate(candidate_lower):
                original_cand = candidate_skills[j] if j < len(candidate_skills) else cand_skill

                if (req_skill in cand_skill or cand_skill in req_skill) and len(req_skill) > 3:
                    matched.append(f"{original_req} (partial)")
                    partial_matches += 0.7
                    found_match = True
                    if debug:
                        print(f"    🔶 PARTIAL: '{original_req}' ~ '{original_cand}'")
                    break

            if found_match:
                continue

            # 3. Common variations - EXPANDED
            variations = {
                'sql': ['database', 'mysql', 'postgresql', 'db', 'database administrator', 'database administration'],
                'python': ['py', 'python programming', 'programming python'],
                'javascript': ['js', 'java script', 'js programming'],
                'communication skills': ['communication skill', 'communication', 'interpersonal skills'],
                'problem solving': ['problem-solving', 'troubleshooting', 'problem solving skills'],
                'customer services': ['customer service', 'customer support', 'customer care'],
                'machine learning': ['ml', 'artificial intelligence', 'ai', 'data science'],
                'web development': ['web dev', 'web programming', 'website development'],
                'html': ['html5', 'hypertext markup', 'web markup'],
                'css': ['css3', 'cascading style', 'styling'],
                'php': ['php programming', 'hypertext preprocessor', 'server-side programming'],
                'network': ['networking', 'computer network', 'network administration'],
                'teamwork': ['team work', 'collaboration', 'team player'],
                'leadership': ['lead', 'management', 'team lead'],
                'quality assurance': ['qa', 'quality control', 'testing'],
                'amazon cloud watch': ['cloudwatch', 'aws cloudwatch', 'cloud monitoring'],
                'mongodb': ['mongo db', 'nosql', 'document database'],
                'postman': ['api testing', 'rest client'],
                'filezila': ['ftp', 'file transfer'],
                'zendesk': ['ticketing system', 'helpdesk'],
                'jira': ['project management', 'issue tracking']
            }

            for j, cand_skill in enumerate(candidate_lower):
                original_cand = candidate_skills[j] if j < len(candidate_skills) else cand_skill

                for variation in variations.get(req_skill, []):
                    if variation in cand_skill:
                        matched.append(f"{original_req} (variation)")
                        partial_matches += 0.5
                        found_match = True
                        if debug:
                            print(f"    🔀 VARIATION: '{original_req}' ~ '{original_cand}' (via {variation})")
                        break
                if found_match:
                    break

        # Calculate final score
        total_score = exact_matches + partial_matches
        final_score = total_score / len(required_skills) if required_skills else 0

        return min(1.0, final_score), matched

print("✅ CompleteCVRecommendationSystem class defined")

"""# **3. Data Loading & Processing**"""

def load_and_process_data():
    """
    Load dan process data kandidat dari CSV

    Process:
    1. Load CSV file
    2. Extract features (skills, experience, salary)
    3. Clean dan normalize data
    4. Create combined text untuk TF-IDF

    Returns:
        CompleteCVRecommendationSystem: Initialized system dengan processed data
    """
    print("="*60)
    print("LOADING AND PROCESSING DATA")
    print("="*60)

    try:
        df = pd.read_csv('data_kandidat.csv')
        print(f"✅ Data loaded: {len(df)} candidates")
    except:
        print("❌ Cannot load CSV file")
        return None

    cv_system = CompleteCVRecommendationSystem()

    # Basic preprocessing functions
    def extract_experience_years(exp_text):
        if pd.isna(exp_text):
            return 0
        years = re.findall(r'(\d+)\s*(?:tahun|years?)', str(exp_text).lower())
        return int(years[0]) if years else 0

    def calculate_age(birth_date):
        if pd.isna(birth_date):
            return 25
        try:
            for fmt in ['%Y-%m-%d', '%d/%m/%Y', '%m/%d/%Y', '%d-%m-%Y']:
                try:
                    birth = datetime.strptime(str(birth_date), fmt).date()
                    today = date.today()
                    age = today.year - birth.year - ((today.month, today.day) < (birth.month, birth.day))
                    return max(16, min(65, age))
                except ValueError:
                    continue
            return 25
        except:
            return 25

    def normalize_salary(salary_text):
        if pd.isna(salary_text):
            return 5000000
        numbers = re.findall(r'\d+', str(salary_text).replace(',', '').replace('.', ''))
        if numbers:
            salary = int(numbers[0])
            if salary < 1000:
                salary *= 1000000
            elif salary < 100000:
                salary *= 1000
            return max(2000000, min(100000000, salary))
        return 5000000

    # Apply preprocessing
    print("🔄 Extracting features...")
    df['skills_list'] = df['Skills'].apply(cv_system.extract_skills_list)
    df['skills_count'] = df['skills_list'].apply(len)
    df['experience_years'] = df['Experience'].apply(extract_experience_years)
    df['age'] = df['Date of birth'].apply(calculate_age)
    df['expected_salary_normalized'] = df['Expected salary (IDR)'].apply(normalize_salary)

    # Fill missing values
    df = df.fillna({
        'Desired positions': 'General',
        'Experience': 'Fresh Graduate',
        'Highest formal of education': 'Bachelor',
        'Faculty/Major': 'General',
        'Skills': '',
        'Current address': 'Unknown',
        'Current status': 'Available'
    })

    # Create text features untuk content-based filtering
    df['skills_text'] = df['skills_list'].apply(lambda x: ' '.join(x))
    df['skills_cleaned'] = df['skills_text'].apply(cv_system.preprocess_text)

    df['combined_text'] = (
        df['skills_cleaned'] + ' ' +
        df['skills_cleaned'] + ' ' +  # Emphasize skills
        df['Desired positions'].apply(cv_system.preprocess_text) + ' ' +
        df['Faculty/Major'].apply(cv_system.preprocess_text)
    )

    cv_system.candidates_data = df
    cv_system.training_date = datetime.now()

    print(f"✅ Processing complete:")
    print(f"   - Average skills per candidate: {df['skills_count'].mean():.1f}")
    print(f"   - Experience range: {df['experience_years'].min()}-{df['experience_years'].max()} years")
    print(f"   - Salary range: Rp {df['expected_salary_normalized'].min():,.0f} - Rp {df['expected_salary_normalized'].max():,.0f}")

    return cv_system

print("✅ Data loading function defined")

"""# **4. Model Training**

## 4.1 Content-Based Filtering Training
"""

def train_content_based_models(cv_system):
    """
    Train Content-Based Filtering models

    Models:
    1. Skills TF-IDF: Specialized untuk skills matching
    2. Content TF-IDF: Combined text (skills + position + major)

    Args:
        cv_system: System instance dengan processed data

    Returns:
        cv_system: System dengan trained content-based models
    """
    print("\n" + "="*60)
    print("TRAINING CONTENT-BASED MODELS")
    print("="*60)

    # 1. Skills TF-IDF
    print("🤖 Training Skills TF-IDF vectorizer...")
    cv_system.skills_tfidf_vectorizer = TfidfVectorizer(
        max_features=3000,
        ngram_range=(1, 3),
        min_df=1,
        max_df=0.95,
        lowercase=True,
        stop_words=None
    )

    skills_texts = cv_system.candidates_data['skills_cleaned'].fillna('')
    cv_system.skills_tfidf_matrix = cv_system.skills_tfidf_vectorizer.fit_transform(skills_texts)

    # 2. Content TF-IDF (combined text)
    print("🤖 Training Content TF-IDF vectorizer...")
    cv_system.content_tfidf_vectorizer = TfidfVectorizer(
        max_features=5000,
        ngram_range=(1, 2),
        min_df=1,
        max_df=0.95,
        lowercase=True,
        stop_words='english'
    )

    combined_texts = cv_system.candidates_data['combined_text'].fillna('')
    cv_system.content_tfidf_matrix = cv_system.content_tfidf_vectorizer.fit_transform(combined_texts)

    print(f"✅ Content-based models trained:")
    print(f"   - Skills TF-IDF matrix: {cv_system.skills_tfidf_matrix.shape}")
    print(f"   - Content TF-IDF matrix: {cv_system.content_tfidf_matrix.shape}")
    print(f"   - Skills vocabulary: {len(cv_system.skills_tfidf_vectorizer.vocabulary_)}")
    print(f"   - Content vocabulary: {len(cv_system.content_tfidf_vectorizer.vocabulary_)}")

    return cv_system

print("✅ Content-based training function defined")

"""## 4.2 Collaborative Filtering Training"""

def train_collaborative_filtering_models(cv_system):
    """
    Train Collaborative Filtering models menggunakan Matrix Factorization

    Process:
    1. Create user-item matrix (candidates vs skills)
    2. Train SVD model untuk dimensionality reduction
    3. Generate predicted interactions

    Args:
        cv_system: System instance dengan processed data

    Returns:
        cv_system: System dengan trained collaborative filtering models
    """
    print("\n" + "="*60)
    print("TRAINING COLLABORATIVE FILTERING MODELS")
    print("="*60)

    # Create user-item matrix berdasarkan skills
    print("🔄 Creating user-item interaction matrix...")

    candidates_skills = cv_system.candidates_data['skills_list'].tolist()
    n_candidates = len(candidates_skills)

    # Get all unique skills
    all_skills = set()
    for skills_list in candidates_skills:
        all_skills.update([skill.lower().strip() for skill in skills_list])

    all_skills = list(all_skills)

    # Create binary interaction matrix
    interaction_matrix = np.zeros((n_candidates, len(all_skills)))

    for i, skills_list in enumerate(candidates_skills):
        for skill in skills_list:
            skill_clean = skill.lower().strip()
            if skill_clean in all_skills:
                j = all_skills.index(skill_clean)
                interaction_matrix[i][j] = 1

    cv_system.user_item_matrix = pd.DataFrame(
        interaction_matrix,
        index=range(n_candidates),
        columns=all_skills
    )

    # Train SVD model
    print("🤖 Training SVD matrix factorization...")

    n_components = min(50, min(cv_system.user_item_matrix.shape) - 1)

    if n_components >= 1:
        cv_system.svd_model = TruncatedSVD(n_components=n_components, random_state=42)
        cv_system.user_factors = cv_system.svd_model.fit_transform(cv_system.user_item_matrix)
        cv_system.item_factors = cv_system.svd_model.components_
        cv_system.predicted_interactions = np.dot(cv_system.user_factors, cv_system.item_factors)

        print(f"✅ Collaborative filtering models trained:")
        print(f"   - User-item matrix: {cv_system.user_item_matrix.shape}")
        print(f"   - SVD components: {n_components}")
        print(f"   - User factors: {cv_system.user_factors.shape}")
        print(f"   - Item factors: {cv_system.item_factors.shape}")
        print(f"   - Explained variance: {cv_system.svd_model.explained_variance_ratio_.sum():.4f}")
    else:
        print("⚠️ Not enough data for collaborative filtering")

    return cv_system

print("✅ Collaborative filtering training function defined")

"""# **5. Job Profiles Creation**"""

def create_job_profiles(cv_system):
    """
    Create comprehensive job profiles dengan skills requirements

    Job Profiles:
    1. Machine Learning Engineer
    2. Technical Support Engineer
    3. Web Developer
    4. Data Analyst

    Args:
        cv_system: System instance

    Returns:
        job_profiles: Dictionary of job profiles
    """
    print("\n" + "="*60)
    print("CREATING JOB PROFILES")
    print("="*60)

    job_profiles = {
        'ml_engineer': {
            'title': 'Machine Learning Engineer',
            'description': 'ML Engineer untuk deployment dan productionize machine learning models',
            'required_skills': ['SQL', 'Amazon Cloud Watch', 'Zendesk', 'Jira', 'MongoDB', 'Postman', 'FileZila'],
            'preferred_skills': ['python', 'machine learning', 'tensorflow', 'pytorch', 'docker', 'kubernetes'],
            'min_experience': 2,
            'max_experience': 8,
            'preferred_education': 'Bachelor',
            'salary_range': (12000000, 25000000),
            'keywords': ['machine learning', 'mlops', 'deployment', 'engineering', 'production']
        },

        'technical_support': {
            'title': 'Technical Support Engineer',
            'description': 'Technical support engineer untuk troubleshooting dan customer support',
            'required_skills': ['Communication Skills', 'Problem Solving', 'Teamwork', 'Customer Services'],
            'preferred_skills': ['Network Performance Optimization', 'Mikrotik Configuration', 'Troubleshooting', 'Hardware'],
            'min_experience': 0,
            'max_experience': 5,
            'preferred_education': 'Bachelor',
            'salary_range': (5000000, 12000000),
            'keywords': ['technical support', 'helpdesk', 'troubleshooting', 'customer service']
        },

        'web_developer': {
            'title': 'Web Developer',
            'description': 'Web developer untuk pengembangan aplikasi web',
            'required_skills': ['HTML', 'CSS', 'PHP', 'JavaScript'],
            'preferred_skills': ['Laravel', 'MySQL', 'Bootstrap', 'JQuery', 'Database Administration'],
            'min_experience': 1,
            'max_experience': 6,
            'preferred_education': 'Bachelor',
            'salary_range': (6000000, 15000000),
            'keywords': ['web development', 'programming', 'frontend', 'backend']
        },

        'data_analyst': {
            'title': 'Data Analyst',
            'description': 'Data analyst untuk analisis data dan reporting',
            'required_skills': ['SQL', 'Excel', 'Data Analysis'],
            'preferred_skills': ['Python', 'Tableau', 'Power BI', 'Statistics', 'Reporting'],
            'min_experience': 0,
            'max_experience': 4,
            'preferred_education': 'Bachelor',
            'salary_range': (7000000, 15000000),
            'keywords': ['data analysis', 'reporting', 'dashboard', 'business intelligence']
        }
    }

    # Process job profiles untuk TF-IDF
    for job_id, profile in job_profiles.items():
        # Create job text untuk content-based matching
        job_text = f"{profile['title']} {profile['description']}"

        # Add skills
        all_skills = profile['required_skills'] + profile['preferred_skills']
        skills_text = ' '.join(all_skills)

        # Add keywords
        keywords_text = ' '.join(profile['keywords'])

        # Combined job text
        full_job_text = f"{job_text} {skills_text} {skills_text} {keywords_text}"

        profile['processed_skills_text'] = cv_system.preprocess_text(skills_text)
        profile['processed_full_text'] = cv_system.preprocess_text(full_job_text)

    cv_system.job_profiles = job_profiles

    for job_id, profile in job_profiles.items():
        print(f"✅ Created: {profile['title']}")
        print(f"   Required: {', '.join(profile['required_skills'])}")
        print(f"   Preferred: {', '.join(profile['preferred_skills'])}")

    return job_profiles

print("✅ Job profiles creation function defined")

"""# **6. Hybrid Recommendations Generation**"""

def get_hybrid_recommendations(cv_system, job_id, top_k=5, debug=False):
    """
    Generate hybrid recommendations menggunakan semua metode

    Scoring Weights:
    - Skills Matching: 40%
    - Content-Based: 25%
    - Collaborative Filtering: 20%
    - Feature-Based: 15%

    Args:
        cv_system: Trained system instance
        job_id: Job identifier
        top_k: Number of recommendations
        debug: Show debug information

    Returns:
        recommendations: List of candidate recommendations dengan detailed scoring
    """
    if job_id not in cv_system.job_profiles:
        raise ValueError(f"Job '{job_id}' not found")

    job_profile = cv_system.job_profiles[job_id]
    required_skills = job_profile['required_skills']
    preferred_skills = job_profile['preferred_skills']

    print(f"\n🔍 Getting hybrid recommendations for: {job_profile['title']}")
    if debug:
        print(f"Required Skills: {', '.join(required_skills)}")
        print(f"Preferred Skills: {', '.join(preferred_skills)}")

    n_candidates = len(cv_system.candidates_data)

    # 1. SKILLS MATCHING SCORE (40% weight)
    skills_scores = np.zeros(n_candidates)
    all_matched_required = []
    all_matched_preferred = []

    for i, candidate in cv_system.candidates_data.iterrows():
        candidate_skills = candidate['skills_list']

        required_score, matched_req = cv_system.calculate_skills_match(
            candidate_skills, required_skills, debug=False
        )
        preferred_score, matched_pref = cv_system.calculate_skills_match(
            candidate_skills, preferred_skills, debug=False
        )

        all_matched_required.append(matched_req)
        all_matched_preferred.append(matched_pref)

        skills_scores[i] = required_score + (preferred_score * 0.3)

    # 2. CONTENT-BASED SIMILARITY (25% weight)
    content_scores = np.zeros(n_candidates)

    if cv_system.skills_tfidf_matrix is not None:
        # Skills similarity
        try:
            job_skills_tfidf = cv_system.skills_tfidf_vectorizer.transform([job_profile['processed_skills_text']])
            skills_similarities = cosine_similarity(job_skills_tfidf, cv_system.skills_tfidf_matrix).flatten()
        except:
            skills_similarities = np.zeros(n_candidates)

        # Content similarity
        try:
            job_content_tfidf = cv_system.content_tfidf_vectorizer.transform([job_profile['processed_full_text']])
            content_similarities = cosine_similarity(job_content_tfidf, cv_system.content_tfidf_matrix).flatten()
        except:
            content_similarities = np.zeros(n_candidates)

        # Weighted combination with minimum baseline
        content_scores = (skills_similarities * 0.7) + (content_similarities * 0.3)

        # Add small baseline untuk prevent 0.0% yang aneh
        content_scores = np.maximum(content_scores, 0.01)  # Minimum 1%

    # 3. COLLABORATIVE FILTERING SCORE (20% weight)
    collab_scores = np.zeros(n_candidates)

    if cv_system.predicted_interactions is not None:
        # Find best matching skills in collaborative space
        job_skills_lower = [skill.lower().strip() for skill in required_skills + preferred_skills]

        if hasattr(cv_system.user_item_matrix, 'columns'):
            skill_matches = []
            for job_skill in job_skills_lower:
                for col_skill in cv_system.user_item_matrix.columns:
                    if job_skill in col_skill or col_skill in job_skill:
                        skill_matches.append(col_skill)

            if skill_matches:
                # Average predictions for matched skills
                matched_indices = [list(cv_system.user_item_matrix.columns).index(skill)
                                 for skill in skill_matches if skill in cv_system.user_item_matrix.columns]

                if matched_indices:
                    collab_scores = np.mean(cv_system.predicted_interactions[:, matched_indices], axis=1)
                    if collab_scores.max() > 0:
                        collab_scores = collab_scores / collab_scores.max()

    # 4. FEATURE-BASED SCORING (15% weight)
    feature_scores = np.zeros(n_candidates)

    for i, candidate in cv_system.candidates_data.iterrows():
        score = 0

        # Experience scoring
        candidate_exp = candidate['experience_years']
        min_exp = job_profile.get('min_experience', 0)
        max_exp = job_profile.get('max_experience', 100)

        if min_exp <= candidate_exp <= max_exp:
            score += 0.4
        elif candidate_exp < min_exp:
            score += max(0, 0.4 - (min_exp - candidate_exp) * 0.1)
        else:
            score += max(0, 0.4 - (candidate_exp - max_exp) * 0.05)

        # Education scoring
        candidate_edu = str(candidate['Highest formal of education']).lower()
        preferred_edu = job_profile.get('preferred_education', '').lower()

        if preferred_edu in candidate_edu:
            score += 0.3
        elif 'master' in candidate_edu or 's2' in candidate_edu:
            score += 0.25
        elif 'bachelor' in candidate_edu or 's1' in candidate_edu:
            score += 0.2

        # Salary compatibility
        candidate_salary = candidate['expected_salary_normalized']
        min_salary, max_salary = job_profile.get('salary_range', (0, 999999999))

        if min_salary <= candidate_salary <= max_salary:
            score += 0.3
        elif candidate_salary < min_salary:
            score += max(0.1, min(0.3, candidate_salary / min_salary))
        else:
            score += max(0.1, min(0.3, min_salary / candidate_salary))

        feature_scores[i] = score

    # HYBRID FINAL SCORING
    final_scores = (
        skills_scores * 0.40 +      # Skills matching (40%)
        content_scores * 0.25 +     # Content-based (25%)
        collab_scores * 0.20 +      # Collaborative filtering (20%)
        feature_scores * 0.15       # Feature-based (15%)
    )

    # Create recommendations
    recommendations = []
    top_indices = np.argsort(final_scores)[::-1][:top_k]

    for rank, idx in enumerate(top_indices, 1):
        candidate = cv_system.candidates_data.iloc[idx]

        matched_required_clean = [skill.split(' (')[0] for skill in all_matched_required[idx]]
        matched_preferred_clean = [skill.split(' (')[0] for skill in all_matched_preferred[idx]]

        recommendation = {
            'rank': rank,
            'candidate_index': idx,
            'name': candidate.get('Full name', 'Unknown'),
            'email': candidate.get('Email address', ''),
            'phone': candidate.get('WhatsApp number', ''),
            'desired_position': candidate.get('Desired positions', ''),
            'education': candidate.get('Highest formal of education', ''),
            'major': candidate.get('Faculty/Major', ''),
            'experience_years': int(candidate.get('experience_years', 0)),
            'expected_salary': int(candidate.get('expected_salary_normalized', 0)),
            'current_status': candidate.get('Current status', ''),
            'address': candidate.get('Current address', ''),
            'skills': candidate.get('Skills', ''),
            'skills_list': candidate['skills_list'],
            'skills_count': len(candidate['skills_list']),
            'matched_required_skills': matched_required_clean,
            'matched_preferred_skills': matched_preferred_clean,
            'skills_match_score': round(skills_scores[idx] * 100, 1),
            'content_similarity_score': round(content_scores[idx] * 100, 1),
            'collaborative_score': round(collab_scores[idx] * 100, 1),
            'feature_score': round(feature_scores[idx] * 100, 1),
            'final_score': round(final_scores[idx] * 100, 1)
        }

        recommendations.append(recommendation)

    return recommendations

print("✅ Hybrid recommendations function defined")

"""# **7. Model Saving & Loading**

## 7.1 Model Saving
"""

def save_model(cv_system, filename='cv_recommendation_model.pkl'):
    """
    Save trained model ke file pickle

    Saved Components:
    - Candidates data
    - All vectorizers dan matrices
    - Collaborative filtering model
    - Job profiles
    - Model metadata

    Args:
        cv_system: Trained system instance
        filename: Output filename
    """
    print("\n" + "="*60)
    print("SAVING MODEL")
    print("="*60)

    model_data = {
        'model_version': cv_system.model_version,
        'training_date': cv_system.training_date,
        'candidates_data': cv_system.candidates_data,
        'skills_tfidf_vectorizer': cv_system.skills_tfidf_vectorizer,
        'skills_tfidf_matrix': cv_system.skills_tfidf_matrix,
        'content_tfidf_vectorizer': cv_system.content_tfidf_vectorizer,
        'content_tfidf_matrix': cv_system.content_tfidf_matrix,
        'user_item_matrix': cv_system.user_item_matrix,
        'svd_model': cv_system.svd_model,
        'user_factors': cv_system.user_factors,
        'item_factors': cv_system.item_factors,
        'predicted_interactions': cv_system.predicted_interactions,
        'job_profiles': cv_system.job_profiles
    }

    try:
        with open(filename, 'wb') as f:
            pickle.dump(model_data, f, protocol=pickle.HIGHEST_PROTOCOL)

        file_size = os.path.getsize(filename) / (1024 * 1024)  # MB
        print(f"✅ Model saved successfully:")
        print(f"   - Filename: {filename}")
        print(f"   - Size: {file_size:.2f} MB")
        print(f"   - Training date: {cv_system.training_date}")
        print(f"   - Model version: {cv_system.model_version}")

    except Exception as e:
        print(f"❌ Error saving model: {e}")

print("✅ Model saving function defined")

"""## 7.2 Model Loading"""

def load_model(filename='cv_recommendation_model.pkl'):
    """
    Load trained model dari file pickle

    Args:
        filename: Model filename

    Returns:
        cv_system: Loaded system instance atau None jika gagal
    """
    print("\n" + "="*60)
    print("LOADING MODEL")
    print("="*60)

    try:
        with open(filename, 'rb') as f:
            model_data = pickle.load(f)

        cv_system = CompleteCVRecommendationSystem()

        # Restore all components
        cv_system.model_version = model_data['model_version']
        cv_system.training_date = model_data['training_date']
        cv_system.candidates_data = model_data['candidates_data']
        cv_system.skills_tfidf_vectorizer = model_data['skills_tfidf_vectorizer']
        cv_system.skills_tfidf_matrix = model_data['skills_tfidf_matrix']
        cv_system.content_tfidf_vectorizer = model_data['content_tfidf_vectorizer']
        cv_system.content_tfidf_matrix = model_data['content_tfidf_matrix']
        cv_system.user_item_matrix = model_data['user_item_matrix']
        cv_system.svd_model = model_data['svd_model']
        cv_system.user_factors = model_data['user_factors']
        cv_system.item_factors = model_data['item_factors']
        cv_system.predicted_interactions = model_data['predicted_interactions']
        cv_system.job_profiles = model_data['job_profiles']

        file_size = os.path.getsize(filename) / (1024 * 1024)
        print(f"✅ Model loaded successfully:")
        print(f"   - Filename: {filename}")
        print(f"   - Size: {file_size:.2f} MB")
        print(f"   - Training date: {cv_system.training_date}")
        print(f"   - Model version: {cv_system.model_version}")
        print(f"   - Candidates: {len(cv_system.candidates_data)}")
        print(f"   - Job profiles: {len(cv_system.job_profiles)}")

        return cv_system

    except FileNotFoundError:
        print(f"❌ Model file '{filename}' not found")
        return None
    except Exception as e:
        print(f"❌ Error loading model: {e}")
        return None

print("✅ Model loading function defined")

"""# **8. Results Display & Analysis**

## 8.1 Display Recommendations
"""

def display_recommendations(recommendations, job_title, show_debug=True):
    """
    Display recommendations dengan format lengkap dan debug info

    Args:
        recommendations: List of candidate recommendations
        job_title: Job title untuk display
        show_debug: Show debugging information
    """
    print(f"\n{'='*70}")
    print(f"TOP {len(recommendations)} CANDIDATES FOR: {job_title.upper()}")
    print(f"{'='*70}")

    if show_debug:
        print(f"\n📊 SCORING WEIGHTS:")
        print(f"   Skills Matching: 40% | Content-Based: 25% | Collaborative: 20% | Features: 15%")

    for rec in recommendations:
        print(f"\n🏆 RANK {rec['rank']}: {rec['name']}")
        print(f"   📧 Email: {rec['email']}")
        print(f"   🎯 Desired Position: {rec['desired_position']}")
        print(f"   🎓 Education: {rec['education']} - {rec['major']}")
        print(f"   💼 Experience: {rec['experience_years']} tahun")
        print(f"   💰 Expected Salary: Rp {rec['expected_salary']:,}")
        print(f"   🛠️ Total Skills: {rec['skills_count']}")

        # Detailed scoring
        print(f"   📊 SCORING BREAKDOWN:")
        print(f"      Skills Match: {rec['skills_match_score']}% (Weight: 40%)")
        print(f"      Content-Based: {rec['content_similarity_score']}% (Weight: 25%)")
        print(f"      Collaborative: {rec['collaborative_score']}% (Weight: 20%)")
        print(f"      Features: {rec['feature_score']}% (Weight: 15%)")
        print(f"      FINAL SCORE: {rec['final_score']}%")

        # Skills matching dengan lebih detail
        required_count = len(rec['matched_required_skills'])
        preferred_count = len(rec['matched_preferred_skills'])

        if rec['matched_required_skills']:
            print(f"   ✅ Matched Required ({required_count}): {', '.join(rec['matched_required_skills'][:5])}")
            if len(rec['matched_required_skills']) > 5:
                print(f"      + {len(rec['matched_required_skills'])-5} more...")
        else:
            print(f"   ❌ Matched Required: None")

        if rec['matched_preferred_skills']:
            print(f"   ⭐ Matched Preferred ({preferred_count}): {', '.join(rec['matched_preferred_skills'][:3])}")
            if len(rec['matched_preferred_skills']) > 3:
                print(f"      + {len(rec['matched_preferred_skills'])-3} more...")
        else:
            print(f"   ⭐ Matched Preferred: None")

        print(f"   🛠️ All Skills: {str(rec['skills'])[:120]}{'...' if len(str(rec['skills'])) > 120 else ''}")

        # Debug info untuk top candidate
        if rec['rank'] == 1 and show_debug:
            print(f"   🔍 DEBUG INFO:")
            print(f"      Total required skills to match: 7")
            print(f"      Total preferred skills to match: 6")
            print(f"      Skills coverage: {required_count}/7 required, {preferred_count}/6 preferred")

print("✅ Display recommendations function defined")

"""## 8.2 System Performance Evaluation"""

def evaluate_system_performance(cv_system, job_profiles):
    """
    Evaluate sistem performance dan berikan insights

    Evaluations:
    1. Dataset statistics
    2. Model performance metrics
    3. Job coverage analysis

    Args:
        cv_system: Trained system instance
        job_profiles: Job profiles dictionary
    """
    print("\n" + "="*70)
    print("SYSTEM PERFORMANCE EVALUATION")
    print("="*70)

    # Dataset statistics
    df = cv_system.candidates_data
    print(f"📊 DATASET STATISTICS:")
    print(f"   - Total candidates: {len(df)}")
    print(f"   - Average skills per candidate: {df['skills_count'].mean():.1f}")
    print(f"   - Skills range: {df['skills_count'].min()}-{df['skills_count'].max()}")
    print(f"   - Experience range: {df['experience_years'].min()}-{df['experience_years'].max()} years")
    print(f"   - Unique desired positions: {df['Desired positions'].nunique()}")

    # Model performance
    print(f"\n🤖 MODEL PERFORMANCE:")
    print(f"   - Skills vocabulary size: {len(cv_system.skills_tfidf_vectorizer.vocabulary_)}")
    print(f"   - Content vocabulary size: {len(cv_system.content_tfidf_vectorizer.vocabulary_)}")
    if cv_system.svd_model:
        print(f"   - Collaborative filtering explained variance: {cv_system.svd_model.explained_variance_ratio_.sum():.3f}")

    # Job coverage analysis
    print(f"\n🎯 JOB COVERAGE ANALYSIS:")
    for job_id, profile in job_profiles.items():
        print(f"\n   {profile['title']}:")
        required_skills = profile['required_skills']
        preferred_skills = profile['preferred_skills']

        # Count how many candidates have each skill
        skill_coverage = {}
        for skill in required_skills + preferred_skills:
            count = 0
            for skills_list in df['skills_list']:
                if any(skill.lower() in candidate_skill.lower() or
                      candidate_skill.lower() in skill.lower()
                      for candidate_skill in skills_list):
                    count += 1
            skill_coverage[skill] = count

        # Required skills coverage
        req_coverage = [skill_coverage.get(skill, 0) for skill in required_skills]
        avg_req_coverage = sum(req_coverage) / len(req_coverage) if req_coverage else 0

        print(f"      Required skills avg coverage: {avg_req_coverage:.1f}/{len(df)} candidates")
        print(f"      Best covered required skill: {max(required_skills, key=lambda x: skill_coverage.get(x, 0))} ({max(req_coverage)}/{len(df)})")
        print(f"      Worst covered required skill: {min(required_skills, key=lambda x: skill_coverage.get(x, 0))} ({min(req_coverage)}/{len(df)})")

print("✅ System evaluation function defined")

"""## 8.3 Detailed Candidate Analysis"""

def get_detailed_analysis(cv_system, job_id, candidate_name):
    """
    Get detailed analysis untuk specific candidate dan job

    Analysis:
    1. Skills breakdown
    2. Required vs preferred skills matching
    3. Missing skills identification
    4. Recommendations untuk improvement

    Args:
        cv_system: Trained system instance
        job_id: Job identifier
        candidate_name: Candidate name
    """
    print(f"\n" + "="*70)
    print(f"DETAILED CANDIDATE ANALYSIS")
    print("="*70)

    # Find candidate
    candidate_row = cv_system.candidates_data[cv_system.candidates_data['Full name'] == candidate_name]
    if candidate_row.empty:
        print(f"❌ Candidate '{candidate_name}' not found")
        return

    candidate = candidate_row.iloc[0]
    job_profile = cv_system.job_profiles[job_id]

    print(f"🔍 ANALYZING: {candidate_name}")
    print(f"📋 FOR JOB: {job_profile['title']}")

    # Skills analysis
    candidate_skills = candidate['skills_list']
    required_skills = job_profile['required_skills']
    preferred_skills = job_profile['preferred_skills']

    print(f"\n🛠️ SKILLS BREAKDOWN:")
    print(f"   Candidate has {len(candidate_skills)} skills")
    print(f"   Job requires {len(required_skills)} skills")
    print(f"   Job prefers {len(preferred_skills)} additional skills")

    # Detailed matching
    req_score, req_matched = cv_system.calculate_skills_match(candidate_skills, required_skills, debug=True)
    print(f"\n✅ REQUIRED SKILLS MATCHING:")
    print(f"   Score: {req_score*100:.1f}%")
    print(f"   Matched: {req_matched}")

    pref_score, pref_matched = cv_system.calculate_skills_match(candidate_skills, preferred_skills, debug=True)
    print(f"\n⭐ PREFERRED SKILLS MATCHING:")
    print(f"   Score: {pref_score*100:.1f}%")
    print(f"   Matched: {pref_matched}")

    # Recommendations
    print(f"\n💡 RECOMMENDATIONS:")
    missing_required = [skill for skill in required_skills if not any(skill.lower() in matched.lower() for matched in req_matched)]
    if missing_required:
        print(f"   Critical missing skills: {', '.join(missing_required)}")
    else:
        print(f"   ✅ All required skills covered!")

    missing_preferred = [skill for skill in preferred_skills if not any(skill.lower() in matched.lower() for matched in pref_matched)]
    if missing_preferred:
        print(f"   Suggested additional skills: {', '.join(missing_preferred[:3])}")

print("✅ Detailed analysis function defined")

"""# **9. Main Execution Functions**

## 9.1 Main Training Function
"""

def main(save_model_flag=True, model_filename='cv_recommendation_model.pkl', show_evaluation=True):
    """
    Main function untuk training complete system

    Process:
    1. Load dan process data
    2. Train content-based models
    3. Train collaborative filtering models
    4. Create job profiles
    5. Save model (optional)
    6. System evaluation (optional)
    7. Generate sample recommendations

    Args:
        save_model_flag: Whether to save trained model
        model_filename: Output model filename
        show_evaluation: Show system evaluation

    Returns:
        tuple: (cv_system, job_profiles)
    """
    print("🚀 STARTING COMPLETE CV RECOMMENDATION SYSTEM")
    print("="*70)

    # Load and process data
    cv_system = load_and_process_data()
    if cv_system is None:
        return None

    # Train all models
    cv_system = train_content_based_models(cv_system)
    cv_system = train_collaborative_filtering_models(cv_system)

    # Create job profiles
    job_profiles = create_job_profiles(cv_system)

    # Save model jika diminta
    if save_model_flag:
        save_model(cv_system, model_filename)

    # System evaluation
    if show_evaluation:
        evaluate_system_performance(cv_system, job_profiles)

    # Generate recommendations
    print("\n" + "="*70)
    print("GENERATING HYBRID RECOMMENDATIONS")
    print("="*70)

    for job_id, job_profile in job_profiles.items():
        recommendations = get_hybrid_recommendations(cv_system, job_id, top_k=5)
        display_recommendations(recommendations, job_profile['title'], show_debug=(job_id=='ml_engineer'))

        # Detailed analysis untuk top candidate
        if recommendations and job_id == 'ml_engineer':
            top_candidate = recommendations[0]['name']
            get_detailed_analysis(cv_system, job_id, top_candidate)

    return cv_system, job_profiles

print("✅ Main training function defined")

"""## 9.2 Demo Load Model Function"""

def demo_load_model(model_filename='cv_recommendation_model.pkl'):
    """
    Demo loading model dan generate recommendations

    Use Case:
    - Load pre-trained model
    - Generate recommendations tanpa training ulang
    - Perfect untuk production usage

    Args:
        model_filename: Model filename to load

    Returns:
        cv_system: Loaded system instance
    """
    print("🔄 DEMO: LOADING SAVED MODEL")
    print("="*70)

    cv_system = load_model(model_filename)
    if cv_system is None:
        print("❌ Cannot load model. Train model first using main()")
        return

    print("\n🎯 Generating recommendations using loaded model...")

    for job_id, job_profile in cv_system.job_profiles.items():
        recommendations = get_hybrid_recommendations(cv_system, job_id, top_k=3)
        display_recommendations(recommendations, job_profile['title'])

    return cv_system


print("✅ Demo load model function defined")

"""# **10. Execution**"""

# **Load Saved Model** (Fast loading tanpa training):
#    ```python
#    cv_system = demo_load_model()

cv_system, job_profiles = main(
        save_model_flag=True,
        model_filename='my_model.pkl',
        show_evaluation=True
    )

